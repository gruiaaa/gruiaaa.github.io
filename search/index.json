[{"content":"onlineUserPredict 项目复现 项目内容 云计算平台以虚拟机为单位按时计算费用，虚拟机数量与在线用户的人数成正比。准确预测在线用户数量，租用合适数量的虚拟机可以节约大量的费用。\n本项目提出了一个基于双层模型的网络游戏在线用户人数预测方法 N-BEATSx-N-HiTS，其特点是利用N-BEATSx 和 NHiTS 为底层预测模型，以随机森林方法进行结果拟合。\n在一个超大规模真实数据集上验证了该方法，该方法单步预测精度达到 97%，多步预测精度也远高于基线方法。根据预测结果租用合适数量的虚拟机，可以节约 40.09%的虚拟机租用成本。该方法能有效处理样本缺失和突发性在线人数剧烈增加的情况。\n工作环境说明 本地工作节点为10.103.104.117，用户ZSX，密码***\nonlineUserPredict 根目录为/home/ZSX/gr/onlineUserPredict\n工作目录说明 2023/1/13 更新\n# 2023/1/13 更新 # 本地工作目录工作目录为 onlineUserPredict ├── codes │ ├── 00_utils │ │ ├── Untitled.ipynb │ │ └── write2oneCsv.ipynb │ ├── 01_DataJoinAndCount │ │ ├── 01joinedData.ipynb │ │ └── 02timeDuration.ipynb │ └── 02_MissingAnomalyValuesDetectionAndFill │ ├── 01missingValuesDetection.ipynb │ └── 02anomalyValuesDetection.ipynb ├── data │ ├── 00_gameData_exampleFromHYF │ │ ├── clubInfo.csv │ │ ├── club_regtime.csv │ │ ├── t_game_bf.csv │ │ ├── t_game_user_bf.csv │ │ ├── userInfo.csv │ │ └── user_regtime.csv │ ├── 00_gameData_fromCXL │ │ ├── matches_game.csv │ │ └── private_rooms_game_only1part.csv │ ├── 01_timeDurationData │ │ ├── 15min_TimeDuration.csv │ │ ├── 1day_TimeDuration.csv │ │ ├── 30min_TimeDuration.csv │ │ └── 60min_TimeDuration.csv │ └── 02_missingFilledData │ └── filledWith0user.csv └── updateCodesFromJupyter.sh # HDFS 目录为 hdfs dfs -du -h /user/GR/OUPD 20.4 G 61.3 G /user/GR/OUPD/01joinedData 1.3 M 3.8 M /user/GR/OUPD/15min_TimedurationData 26.6 K 79.7 K /user/GR/OUPD/1day_TimedurationData 653.7 K 1.9 M /user/GR/OUPD/30min_TimedurationData 336.5 K 1009.6 K /user/GR/OUPD/60min_TimedurationData 2.2 M 6.6 M /user/GR/OUPD/inOneCSV 7.9 G 23.6 G /user/GR/OUPD/matches_game 73.1 G 219.4 G /user/GR/OUPD/private_rooms_game 数据集准备 原始数据集 某游戏平台连续8个月的真实游戏用户数据和日志数据，数据时间从2020年7月至2021年4月。数据包含用户对局过程中的所有静态和动态信息，共计6个表。\n数据集 文件名 描述 公会信息表 clubinfo.csv 工会ID、工会成员ID 公会注册表 club_regtime.csv 工会ID、工会注册时间 用户注册表 user_regtime.csv 用户ID、用户注册时间 用户信息表 userInfo.csv 用户ID、用户出生日期、用户性别、注册包ID、上次登录时间、上次登录IP 游戏信息表 t_game_user_bf（存疑） 包房 ID、注册时间、用户生日、性别、公会 ID（存疑） 游戏对局表 t_game_bf.csv 用户 ID、桌号、积分、开局时间、结束时间（部分关键字段） clubinfo.csv\nclub_regtime.csv\nuser_regtime.csv\nuserInfo.csv\nt_game_user_bf.csv\nt_game_bf.csv\n数据存疑 2023/1/10\n车论文中所写数据集与关键字段如下\n​\t数据集\t关键字段 ​\t公会信息表 用户 ID、公会 ID ​\t公会注册表 公会 ID、注册时间、机器号、游戏包 ID ​\t用户注册表 用户 ID、公会 ID ​\t用户信息表 性别、用户 ID、注册包、最大游戏局数、底金 ​\t游戏信息表 包房 ID、注册时间、用户生日、性别、公会 ID ​\t游戏对局表 用户 ID、桌号、积分、开局时间、结束时间\n但与胡所给原始数据集样本中字段（如上六图）不能完全对应上，主要体现在t_game_user_bf、t_game_bf两表中。\n应该是车or胡对数据做过一些处理（比如join等），车论文中所用是处理后的结果。\n所以复现流程需从车的数据预处理代码中推测join等操作，但也可不必实现，可直接从\n​\t1 hdfs://10.103.104.134:8020/cxl/second\n​\t2 hdfs://10.103.104.134:8020/cxl/bf_game\n中做数据迁移，在车hdfs数据集基础上复现。\n车\u0026rsquo;s HDFS 数据集 车所给数据集预处理代码为 10.103.104.137:/home/CXL/data_g，复现项目中更名为onlineUserPredict/dataPreprocessing。\n从数据预处理代码（GameData.ipynb，Game_Data.ipynb，OnlineUsers2.ipynb）推断，预处理所用到的数据集主要有两个\nhdfs://10.103.104.134:8020/cxl/second\n$ hdfs dfs -du -h /cxl/second 0 0 /cxl/second/_SUCCESS 7.9 G 15.7 G /cxl/second/part-00000-bc1fca6b-0e9c-4507-b9d6-08989c6bf349-c000.csv $ hdfs dfs -head /cxl/second/part-00000-bc1fca6b-0e9c-4507-b9d6-08989c6bf349-c000.csv bfid,uid,dday,clubid,btime,etime,RegistrationTime,birthDate,sex,注册包ID 244038614,12032582,20200908,32216,1599493941,1599494864,2017-1-7 14:13:21,19881112,0,10000 251710270,12422335,20201003,31195,1601733783,1601734808,2017-1-20 11:49:34,19671105,0,10000 231202450,13348468,20200727,81021,1595810079,1595863060,2017-2-12 20:04:59,19900506,0,10001 234981242,13545198,20200808,504168,1596901605,1596903717,2017-2-17 20:53:54,19960618,1,10016 272011824,14097400,20201209,45865,1607519555,1607521973,2017-3-3 20:25:59,19740426,1,10000 294998062,14229527,20210215,562312,1613358208,1613364462,2017-3-7 13:57:12,19900430,1,10001 258067415,14708172,20201025,35245,1603606774,1603608798,2017-3-19 18:48:00,19690513,1,10000 315071691,14823926,20210408,0,1617894298,1617894914,2017-3-23 13:49:38,19770131,1,10031 253153012,14853284,20201008,529166,1602163848,1602164722,2017-3-24 00:25:37,19760114,0,10016 275062425,15474830,20201219,0,1608365000,1608365120,2017-4-10 16:07:21,19800928,0,10025 hdfs://10.103.104.134:8020/cxl/bf_game\n$ hdfs dfs -du -h /cxl/bf_game 73.1 G 146.3 G /cxl/bf_game/20200727-20210310 $ hdfs dfs -du -h /cxl/bf_game/20200727-20210310 0 0 /cxl/bf_game/20200727-20210310/_SUCCESS 128.3 M 256.6 M /cxl/bf_game/20200727-20210310/part-00000-8bd6c170-68c8-47b0-a505-305edf56c294-c000.csv 128.3 M 256.6 M /cxl/bf_game/20200727-20210310/part-00001-8bd6c170-68c8-47b0-a505-305edf56c294-c000.csv 128.3 M 256.6 M /cxl/bf_game/20200727-20210310/part-00002-8bd6c170-68c8-47b0-a505-305edf56c294-c000.csv ... 69.8 M 139.7 M /cxl/bf_game/20200727-20210310/part-00614-8bd6c170-68c8-47b0-a505-305edf56c294-c000.csv 41.6 M 83.2 M /cxl/bf_game/20200727-20210310/part-00615-8bd6c170-68c8-47b0-a505-305edf56c294-c000.csv $ hdfs dfs -head /cxl/bf_game/20200727-20210310/part-00000-8bd6c170-68c8-47b0-a505-305edf56c294-c000.csv autoid,machid,bfpwd,host,dijin,currju,maxju,costtype,cost,rule1,rule2,rule3,rule4,rule5,rule6,btime,wtime,etime,dday,mtype,real_num,rated_num,jifen,pai0,pai1,pai2,pai3,pai4,pai5,state,gameid,clubid,apkid,appid,copen_num,opuid 231155900,0,393098,0,90,1,1,0,0,67174657,16777216,0,0,0,0,1595779200,1595779200,1595779318,20200727,\u0026quot;\u0026quot;,\\0 从文件命名格式可看出这两个文件夹是spark处理后的结果。second文件夹下仅一个part，大小为7.9G。bf_game/20200727-20210310文件夹下共616个part，总大小为73.1G。\n进行数据迁移并重命名。在此数据集基础上复现。\n数据集 文件夹名 大小 描述 HDFS Url 对局信息 matches_game 7.9G 每一对局的信息，包含用户ID，用户所属工会ID，起止时间等 hdfs://10.103.104.117:9000\n/user/GR/OUPD/matches_game 包房信息 private_rooms_game 73.1G 每个包房的信息，包含包房的底金，最大对局数、起止时间等 hdfs://10.103.104.117:9000\n/user/GR/OUPD/private_rooms_game 说明：对局信息和包房信息中共同列为对局开始时间、结束时间。（对局要有包房）\n数据预处理流程推断 \u0026amp; 复现 流程推断 通过分析车所给数据预处理代码，得出在预处理阶段主要进行的操作为\n转换时间戳 通过生日计算年龄 对两个表进行join 分段统计在线人数 计算平均值 最终得到的表(部分)如下\ntimeduration avg_dijin avg_maxju avg_cost avg_age number_players 2021-02-12 12:15:00 193.956 6.995 1.491 41.429 3898 2021-02-12 12:30:00 211.957 6.942 1.504 41.808 4080 2021-02-12 12:45:00 245.015 7.075 1.528 42.135 4333 2021-02-12 13:00:00 292.337 7.024 1.524 42.534 4631 表头分别为：时间段、平均底金、平均最大对局、平均花费、平均年龄、在线人数。\n表中时间段划分间隔为15min。\n复现 01joinedData.ipynb\n读取hdfs集群中 matches_game/、private_rooms_game/ 下数据，通过用户生日计算年龄，进行join操作（on=\u0026lsquo;btime\u0026rsquo;, how=\u0026lsquo;left\u0026rsquo;），选取特征列，结果如下图\n结果存储在hdfs://10.103.104.117:9000/user/GR/OUPD/01joinedData，共200个part，总大小为20.4G。\n02timeDuration.ipynb\n读取hdfs://10.103.104.117:9000/user/GR/OUPD/01joinedData，进一步选择特征列select(\u0026ldquo;uid\u0026rdquo;,\u0026ldquo;dday\u0026rdquo;,\u0026ldquo;btime\u0026rdquo;,\u0026ldquo;etime\u0026rdquo;,\u0026ldquo;dijin\u0026rdquo;,\u0026ldquo;maxju\u0026rdquo;,\u0026ldquo;cost\u0026rdquo;,\u0026ldquo;age\u0026rdquo;)，将起止时间从时间戳转换为标准时间格式，通过calcalateOnlineTimeDuration(df,timeDuration=30)函数计算用户上线时间所处于哪个时间段，然后通过groupby和count，计算出每个时间段在线人数以及相应特征列的平均值。结果如下图所示\n​\t结果按时间段间隔命名，存储在HDFS上\n时间段间隔 结果路径 大小 15minn /user/GR/OUPD/15min_TimedurationData 1.3 M 30min /user/GR/OUPD/30min_TimedurationData 653.8 K 60min /user/GR/OUPD/60min_TimedurationData 336.4 K 1day /user/GR/OUPD/1day_TimedurationData 26.6 K 此后项目在此三个数据集上进行。\n数据缺失值检测\u0026amp; 缺失值填充 \u0026amp; 异常值检测 缺失值检测 目的：在1day_TimedurationData基础上检测有无日期缺失。\n01missingValuesDetection.ipynb\n读取数据后通过max、min获取日期的起止时间，得到跨度天数，通过date_range生成起止时间序列，与数据做差集，即可得到数据集中缺失天数。如下图所示\n将缺失值填充为0，画折线图即可直观看到缺失情况，如下图所示，填充结果存储为02_missingFilledData/filledWith0user.csv\n缺失值填充 在1day_TimeDuration.csv上通过缺失值检测可知缺少3天数据集，所以要进行缺失值填充。\n填充方法选取\n异常值检测 异常检测（Anomaly detection）是定义是从正常的时间序列中识别不正常的事件或行为的过程。\n常用的异常检测算法可大致分为以下几种（来自网络，参考1 参考2）\n统计方法\n最常用的方法就是基于k-sigma的同比算法，这是一个快速而且有效的算法。简单来说，即当前数据点的状态由之前不同周期的相同位置数据(比如上周或者前一天的同一时刻)决定，通过历史同期的数据分布来确定当前数据的合理波动范围。它的初始假设，是局部数据符合正态分布。这个算法有效利用了历史同期的数据，避免了全局使用唯一的固定阈值来衡量是否异常，同时还具有算法计算快速、原理易懂可解释的优点。\n预测方法\n预测方法是异常检测中最常用的方法，基本思路是通过比较预测值和真实值的差异，判定是否异常。它包括传统的时序预测模型ARIMA、渐进梯度回归树GBRT、长短时记忆网络LSTM以及Facebook开源算法Prophet等等\n有监督学习\n有监督的算法有很多，如基于树模型的随机森林、lightGBM，神经网络MLP等等，其整体思路是提取各种各样的统计特征（如前几个数据点的原始值，最近一段时间的均值、标准差、偏度等等），直接丢给模型去训练，算法会根据标注自动选择最有效的特征用以建模。有监督算法往往可以获得更高的算法准确度，但缺点也是十分明显的——最大的问题就是，我们需要大量的人工标注，覆盖全面的数据类型和异常情况，而这在实际场景中是极难实现的。实际生产中，我们极少考虑这类算法，除非异常场景很明确且历史中存在多次相似的情况。\n深度学习检测\n最近几年，通过深度学习生成模型来做异常检测的算法越来越多，效果甚至可以超过一般的有监督学习方法。主要可以分为以下这么几种\na) 针对正常数据进行训练建模，然后通过高重构误差来识别异常点，即生成式（Generative）的算法，往往是无监督的，如自编码器（Auto Encoder）类或者回声状态网络（Echo State Networks）。生成模型的优势就是算法准确率高、极少人工干预，但单纯的算法仍存在一些不足。如需要长时间表现稳定的历史数据，需要较长的训练时间，且同样会面临衡量差值大小与异常的关系这类问题等等。\nb) 对数据的概率分布进行建模，然后根据样本点与极低概率的关联性来识别异常点，如DAGMM\nc) 通过标注数据，告诉模型正常数据点长什么样，异常数据点长什么样，然后通过有监督算法训练分类模型，也称判别式（Discriminative）算法。\n经过对异常值检测算法的简单了解，我在本项目中决定选用统计方法对异常值进行检测，原因是统计方法可自定义规则，计算快速，原理通俗易懂。\n统计方法中常见的方法如箱型图、3σ方法、分位点法、离群点检测都是基于非时序数据的方法，即它们所检测的是在一个整体数据集的情况下，所有数据偏离整体分布的情况，偏离一定程度即视为异常值。所以以上方法不适用于时序数据的检测。\n定义规则：第N个数据的值处于前7个数据均值上下15%之间时，视为正常值，否则为异常值\n以下在按天数进行异常值检测\n0填充异常值检测 使用填充后的filledWith0user.csv进行异常值检测。\n运行结果如下图\n其中-7dayMean列为前7次数据的平均值，percent为该次数据在前7天平均值上的涨跌比率，anomaly为是否是异常值（超过上下15%）。\n在折线图中标出异常值如下图\n涨跌比率随时间变化如下图\n从图中结果分析，使用在0填充后的数据集上使用前N天均值检测异常值会出现0填充影响正常数据的情况（因为0拉低了平均值），所以使用未进行0填充的数据再进行一遍检测，且使用散点图绘图。\n无填充异常值检测 检测结果分别为\n检测结果分别存储为reslutFilledWith0.csv,reslutNoFilled.csv\n两个结果对比，取交集如下图，只有一个共同值。\n","date":"2023-01-16","permalink":"https://gruiaaa.github.io/post/onlineuserpredict/","tags":null,"title":"OnlineUserPredict"}]