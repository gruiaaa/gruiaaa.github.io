[{"content":"第一章 算法概述 常见的时间复杂度，及其增长速度比较 时间复杂度反映的是随着问题规模的变大，计算所需的时间的增长速度，与系数的多少关系不大\n渐进符号 O 大O 渐进上界 存在两个正常数c和n0，使得当n≥n0时，有f(n)≤cg(n)，则记做f(n) = O(g(n))\n示例\nf(n) = 2n + 3 = O(n)\n当n≥3时，2n+3≤3n，\n所以，可选c = 3，n0 = 3。对于n≥n0，f(n) = 2n + 3≤3n，\n所以， f(n) = O(n) 。这意味着，当n≥3时，该程序步不会超过3n。\nfn的阶不低于On\nΩ 欧米噶 渐近下界 存在两个正常数 c和n0，使得当n≥n0时，有f(n) ≥c g(n)，则记做f(n) = Ω (g(n))\nfn的阶不高于On\n例1-5 f(n) = 2n + 3 =Ω(n)\n对所有n，2n+3≥2n，可选c = 2，n0=0。\n对于n≥n0，f(n) = 2n+3≥2n，所以，f(n) = Ω(n)，即2n + 3∈Ω(n)。\n例1-6 f(n) = 10n2 + 4n + 2 = Ω(n2)\n对所有n，10n2 + 4n + 2≥10n2，可选c = 10，n0 = 0。\n对于n≥n0，f(n) = 10n2 + 4n + 2≥10n2，所以，f(n) =Ω(n^2)。\nθ Theta紧渐近界 存在正常数c1，c2和n0，使得当n≥n0时，有c1 g(n)≤f(n)≤c2 g(n)，则记做f(n) = θ(g(n))\nfn 、On 同阶\n例1-7\nf(n) = 2n + 3 = θ(n)\n例1-8\nf(n) = 10n2 + 4n + 2 = θ(n^2)\n算法按时间复杂度分类 分为\n多项式时间算法\n指数时间算法\n复杂度示意图\n常见排序算法时间复杂度 常用的排序算法的时间复杂度和空间复杂度\n排序法 最差时间分析 平均时间复杂度 稳定度 空间复杂度 冒泡排序 O(n2) O(n2) 稳定 O(1) 插入排序 O(n2) O(n2) 稳定 O(1) 选择排序 O(n2) O(n2) 不稳定 O(1) 二叉树排序 O(n2) O(n*log2n) 不一定 O(n) 快速排序 O(n2) O(n*log2n) 不稳定 O(log2n)~O(n) 堆排序 O(n*log2n) O(n*log2n) 不稳定 O(1) 希尔排序 O(n^(1.3-2)) O(n^(1.3-2)) 不稳定 O(1) 常见查找算法时间复杂度 查找 查找条件 平均时间复杂度 算法描述 顺序查找 无序或有序队列 O(n) 按顺序比较每个元素，直到找到关键字为止 二分查找（折半查找） 有序数组 O(logn) 查找过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜素过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。　如果在某一步骤数组为空，则代表找不到。 二叉排序树查找 二叉排序树 O(logn) 在二叉查找树b中查找x的过程为：1. 若b是空树，则搜索失败2. 若x等于b的根节点的数据域之值，则查找成功；3. 若x小于b的根节点的数据域之值，则搜索左子树4. 查找右子树。 哈希表法（散列表） 先创建哈希表（散列表） O(1) 根据键值方式(Key value)进行查找，通过散列函数，定位数据元素。 分块查找 无序或有序队列 O(logn) 将n个数据元素\u0026quot;按块有序\u0026quot;划分为m块（m ≤ n）。每一块中的结点不必有序，但块与块之间必须\u0026quot;按块有序\u0026quot;；即第1块中任一元素的关键字都必须小于第2块中任一元素的关键字；而第2块中任一元素又都必须小于第3块中的任一元素，……。然后使用二分查找及顺序查找。 P类与NP类 通常将可在多项式时间内解决的问题看作“易”解决的问题，将再指数函数时间解决的问题看作“难”的问题。\n不是所有的问题都可以在多项式时间内求解。\n所有可以在多项式时间内求解的判定问题构成P类问题（Polynomial Problem，多项式问题）。\nP类问题是确定性模型下的易解问题类。\nNP类问题是非确定性计算模型下的易验证问题类\n参考1 参考2 P问题、NP问题、NP完全问题和NP难问题 - 知乎 (zhihu.com) 参考3 简析P和NP问题的概念 - 别再闹了 - 博客园 (cnblogs.com) 第二章 递归与分治策略 ","date":"2023-02-22","permalink":"https://gruiaaa.github.io/post/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/","tags":null,"title":"算法笔记"},{"content":"onlineUserPredict 项目复现 [toc]\n项目说明 项目内容 摘要\n云计算平台以虚拟机为单位按时计算费用，虚拟机数量与在线用户的人数成正比。准确预测在线用户数量，租用合适数量的虚拟机可以节约大量的费用。\n本项目提出了一个基于双层模型的网络游戏在线用户人数预测方法 N-BEATSx-N-HiTS，其特点是利用N-BEATSx 和 NHiTS 为底层预测模型，以随机森林方法进行结果拟合。\n在一个超大规模真实数据集上验证了该方法，该方法单步预测精度达到 97%，多步预测精度也远高于基线方法。根据预测结果租用合适数量的虚拟机，可以节约 40.09%的虚拟机租用成本。该方法能有效处理样本缺失和突发性在线人数剧烈增加的情况。\n工作节点\u0026amp;目录 本地工作节点为10.103.104.117，用户ZSX，密码***。onlineUserPredict 根目录为/home/ZSX/gr/onlineUserPredict\n工作目录\n2023/2/5 更新\n# 2023/2/5 更新\r# 本地工作目录工作目录为\r.\r├── codes\r│ ├── 00_utils\r│ │ ├── Untitled.ipynb\r│ │ └── write2oneCsv.ipynb\r│ ├── 01_joinData\r│ │ └── joinData.ipynb\r│ ├── 02_timeDuration\r│ │ └── timeDuration.ipynb\r│ └── 03_NAOMI\r│ ├── 01missingValuesDetection.ipynb\r│ └── 02anomalyValuesDetection.ipynb\r├── data\r│ ├── 00_gameDataExample\r│ │ ├── fromCXL\r│ │ │ ├── matches_game.csv\r│ │ │ └── private_rooms_game_only1part.csv\r│ │ └── fromHYF\r│ │ ├── clubInfo.csv\r│ │ ├── club_regtime.csv\r│ │ ├── t_game_bf.csv\r│ │ ├── t_game_user_bf.csv\r│ │ ├── userInfo.csv\r│ │ └── user_regtime.csv\r│ ├── 01_joinedData\r│ ├── 02_timeDurationData\r│ │ ├── 15min_TimeDuration.csv\r│ │ ├── 1day_TimeDuration.csv\r│ │ ├── 30min_TimeDuration.csv\r│ │ └── 60min_TimeDuration.csv\r│ └── 03_NAOMI\r│ ├── 1day_timeduration_filledwith0user.csv\r│ ├── anomalyResultFilledWith0_1day_timeduration.csv\r│ └── anomalyResultNoFilled_1day_timeduration.csv\r└── updateCodesFromJupyter.sh\r# HDFS 目录为\rhdfs dfs -du -h /user/GR/OUPD\r20.4 G 61.3 G /user/GR/OUPD/01joinedData\r1.3 M 3.8 M /user/GR/OUPD/15min_TimedurationData\r26.6 K 79.7 K /user/GR/OUPD/1day_TimedurationData\r653.7 K 1.9 M /user/GR/OUPD/30min_TimedurationData\r336.5 K 1009.6 K /user/GR/OUPD/60min_TimedurationData\r2.2 M 6.6 M /user/GR/OUPD/inOneCSV\r7.9 G 23.6 G /user/GR/OUPD/matches_game\r73.1 G 219.4 G /user/GR/OUPD/private_rooms_game\r原项目流程分析 通过分析车所给代码，绘制如下图\n整个项目可分为四个步骤\n对原数据进行join，提取关键属性列（用户在线时间、对局信息等）。 对用户在线时间段进行划分（15min一段、30min一段、1h一段），并进行统计。 使用NAOMI（非自回归多分辨率插补）进行缺失值填充。 完整数据集传入模型，进行训练、预测。 流程复现 00.数据集准备 原始数据集 某游戏平台连续8个月的真实游戏用户数据和日志数据，数据时间从2020年7月至2021年4月。数据包含用户对局过程中的所有静态和动态信息，共计6个表。\n数据集 文件名 描述 详细信息 公会信息表 clubinfo.csv 工会ID、工会成员ID 公会注册表 club_regtime.csv 工会ID、工会注册时间 用户注册表 user_regtime.csv 用户ID、用户注册时间 用户信息表 userInfo.csv 用户ID、用户出生日期、用户性别、注册包ID、上次登录时间、上次登录IP 游戏信息表 t_game_user_bf（存疑） 包房 ID、注册时间、用户生日、性别、公会 ID（存疑） 游戏对局表 t_game_bf.csv 用户 ID、桌号、积分、开局时间、结束时间（部分关键字段） 数据存疑 2023/1/10\n车论文中所写数据集与关键字段如下\n​\t数据集\t关键字段 ​\t公会信息表 用户 ID、公会 ID ​\t公会注册表 公会 ID、注册时间、机器号、游戏包 ID ​\t用户注册表 用户 ID、公会 ID ​\t用户信息表 性别、用户 ID、注册包、最大游戏局数、底金 ​\t游戏信息表 包房 ID、注册时间、用户生日、性别、公会 ID ​\t游戏对局表 用户 ID、桌号、积分、开局时间、结束时间\n但与胡所给原始数据集样本中字段（如上六图）不能完全对应上，主要体现在t_game_user_bf、t_game_bf两表中。\n应该是车or胡对数据做过一些处理（比如join等），车论文中所用是处理后的结果。\n初始数据集无权限获取，所以复现流程在车的数据集基础上进行。\n车\u0026rsquo;s HDFS 数据集 车所给数据集预处理代码为 10.103.104.137:/home/CXL/data_g，从数据预处理代码（GameData.ipynb，Game_Data.ipynb，OnlineUsers2.ipynb）推断，预处理所用到的数据集主要有两个\nhdfs://10.103.104.134:8020/cxl/second\nhdfs://10.103.104.134:8020/cxl/bf_game\n从文件命名格式可看出这两个文件夹是spark处理后的结果。second文件夹下仅一个part，大小为7.9G。bf_game/20200727-20210310文件夹下共616个part，总大小为73.1G。\n进行数据迁移并重命名。在此数据集基础上复现。\n数据集 文件夹名 大小 描述 HDFS Url 对局信息 matches_game 7.9G 每一对局的信息，包含用户ID，用户所属工会ID，起止时间等 hdfs://10.103.104.117:9000\n/user/GR/OUPD/matches_game 包房信息 private_rooms_game 73.1G 每个包房的信息，包含包房的底金，最大对局数、起止时间等 hdfs://10.103.104.117:9000\n/user/GR/OUPD/private_rooms_game 说明：对局信息和包房信息中共同列为对局开始时间、结束时间。（对局要有包房）\n01.joinData joinData.ipynb\n读取hdfs集群中 matches_game/、private_rooms_game/ 下数据，通过用户生日计算年龄，进行join操作（on=\u0026lsquo;btime\u0026rsquo;, how=\u0026lsquo;left\u0026rsquo;），选取特征列，结果如下图\n结果存储在hdfs://10.103.104.117:9000/user/GR/OUPD/01joinedData，共200个part，总大小为20.4G。\n02.timeDuration timeDuration.ipynb\n读取hdfs://10.103.104.117:9000/user/GR/OUPD/01joinedData，进一步选择特征列select(\u0026ldquo;uid\u0026rdquo;,\u0026ldquo;dday\u0026rdquo;,\u0026ldquo;btime\u0026rdquo;,\u0026ldquo;etime\u0026rdquo;,\u0026ldquo;dijin\u0026rdquo;,\u0026ldquo;maxju\u0026rdquo;,\u0026ldquo;cost\u0026rdquo;,\u0026ldquo;age\u0026rdquo;)，将起止时间从时间戳转换为标准时间格式，通过calcalateOnlineTimeDuration(df,timeDuration=30)函数计算用户上线时间所处于哪个时间段，然后通过groupby和count，计算出每个时间段在线人数以及相应特征列的平均值。结果如下图所示\n结果按时间段间隔命名，存储在HDFS上\n时间段间隔 结果路径 大小 15minn /user/GR/OUPD/15min_TimedurationData 1.3 M 30min /user/GR/OUPD/30min_TimedurationData 653.8 K 60min /user/GR/OUPD/60min_TimedurationData 336.4 K 1day /user/GR/OUPD/1day_TimedurationData 26.6 K 此后项目在此数据集上进行。\n03.NAOMI 缺失值检测 目的：在1day_TimedurationData基础上检测数据集有无日期缺失。\n01missingValuesDetection.ipynb\n读取数据后通过max、min获取日期的起止时间，得到跨度天数，通过date_range生成起止时间序列，与数据做差集，即可得到数据集中缺失天数。如下图所示\n将缺失值填充为0，画折线图即可直观看到缺失情况，如下图所示，填充结果存储为03_NAOMI/1day_timeduration_filledwith0user.csv\n异常值检测 异常检测（Anomaly detection）是定义是从正常的时间序列中识别不正常的事件或行为的过程。\n常用的异常检测算法可大致分为以下几种（来自网络，参考1 参考2）\n统计方法\n最常用的方法就是基于k-sigma的同比算法，这是一个快速而且有效的算法。简单来说，即当前数据点的状态由之前不同周期的相同位置数据(比如上周或者前一天的同一时刻)决定，通过历史同期的数据分布来确定当前数据的合理波动范围。它的初始假设，是局部数据符合正态分布。这个算法有效利用了历史同期的数据，避免了全局使用唯一的固定阈值来衡量是否异常，同时还具有算法计算快速、原理易懂可解释的优点。\n预测方法\n预测方法是异常检测中最常用的方法，基本思路是通过比较预测值和真实值的差异，判定是否异常。它包括传统的时序预测模型ARIMA、渐进梯度回归树GBRT、长短时记忆网络LSTM以及Facebook开源算法Prophet等等\n有监督学习\n有监督的算法有很多，如基于树模型的随机森林、lightGBM，神经网络MLP等等，其整体思路是提取各种各样的统计特征（如前几个数据点的原始值，最近一段时间的均值、标准差、偏度等等），直接丢给模型去训练，算法会根据标注自动选择最有效的特征用以建模。有监督算法往往可以获得更高的算法准确度，但缺点也是十分明显的——最大的问题就是，我们需要大量的人工标注，覆盖全面的数据类型和异常情况，而这在实际场景中是极难实现的。实际生产中，我们极少考虑这类算法，除非异常场景很明确且历史中存在多次相似的情况。\n深度学习检测\n最近几年，通过深度学习生成模型来做异常检测的算法越来越多，效果甚至可以超过一般的有监督学习方法。主要可以分为以下这么几种\na) 针对正常数据进行训练建模，然后通过高重构误差来识别异常点，即生成式（Generative）的算法，往往是无监督的，如自编码器（Auto Encoder）类或者回声状态网络（Echo State Networks）。生成模型的优势就是算法准确率高、极少人工干预，但单纯的算法仍存在一些不足。如需要长时间表现稳定的历史数据，需要较长的训练时间，且同样会面临衡量差值大小与异常的关系这类问题等等。\nb) 对数据的概率分布进行建模，然后根据样本点与极低概率的关联性来识别异常点，如DAGMM\nc) 通过标注数据，告诉模型正常数据点长什么样，异常数据点长什么样，然后通过有监督算法训练分类模型，也称判别式（Discriminative）算法。\n经过对异常值检测算法的简单了解，我在本项目中决定选用统计方法对异常值进行检测，原因是统计方法可自定义规则，计算快速，原理通俗易懂。\n统计方法中常见的方法如箱型图、3σ方法、分位点法、离群点检测都是基于非时序数据的方法，即它们所检测的是在一个整体数据集的情况下，所有数据偏离整体分布的情况，偏离一定程度即视为异常值。所以以上方法不适用于时序数据的检测。\n定义规则：第N个数据的值处于前7个数据均值上下15%之间时，视为正常值，否则为异常值\n以1day_timeduration_filledwith0user.csv为例，进行异常值检测\n0填充异常值检测 运行结果如下图\n其中-7dayMean列为前7次数据的平均值，percent为该次数据在前7天平均值上的涨跌比率，anomaly为是否是异常值（超过上下15%）。 -折线图中标出异常值- -涨跌比率随时间变化- 从图中结果分析，使用在0填充后的数据集上使用前N天均值检测异常值会出现0填充影响正常数据的情况（因为0拉低了平均值），所以使用未进行0填充的数据再进行一遍检测，且使用散点图绘图。\n无填充异常值检测 -异常值结果- -在线人数散点图- -异常值标注- 检测结果分别存储为reslutFilledWith0.csv,reslutNoFilled.csv\n两个结果对比，取交集如下图，只有一个共同值。\n缺失值填充 在1day_TimeDuration.csv上通过缺失值检测可知缺少3天数据集，所以要进行缺失值填充。\n填充方法选取NAOMI(非自回归多分辨率插补)进行填充，该方法为论文所提出。\n简要读完论文及代码、查看之前代码的运行记录后，决定在复现中先跳过此步骤，使用之前的填充好的数据集，原因如下：\n填充一个属性列就需要13h+的时间来训练模型，一共需要填充五个，耗时久 NAOMI官方代码修改较麻烦，魔改耗时久 使用torch自建模型不太了解，需要花时间学习 综上，以实现在线人数预测为目的，重点放在在线实现，所以可降低数据缺失值填充重要性，留待之后实现。\n之后使用车所给rawdata文件夹中的填充好的rawdata_15min.csv\n04.N-BEATSx-N-HiTS 2023.02.08 更新\nGPU服务器连接不上，只好搁置，等到校恢复正常后再进行。\n","date":"2023-01-16","permalink":"https://gruiaaa.github.io/post/onlineuserpredict/","tags":null,"title":"OnlineUserPredict"}]